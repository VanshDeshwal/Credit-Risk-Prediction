{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e39a7537",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, StackingClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, precision_recall_fscore_support\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50fb1211",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded = pd.read_csv(\"C:/Github/Credit Risk Prediction/data/processed/df_encoded.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25051c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Separate features and target\n",
    "y = df_encoded['Approved_Flag']\n",
    "X = df_encoded. drop ( ['Approved_Flag'], axis = 1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55246f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Encode labels to integers (e.g. p1, p2, p3, p4 â†’ 0, 1, 2, 3)\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e14d7350",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y_encoded, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "70fda9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale features for SVM\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ecdfecb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.combine import SMOTETomek\n",
    "smote_tomek = SMOTETomek(random_state=42)\n",
    "X_train_balanced, y_train_balanced = smote_tomek.fit_resample(X_train, y_train)\n",
    "X_train_scaled_balanced, _ = smote_tomek.fit_resample(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0857aa36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== RandomForest ===\n",
      "Accuracy: 0.764\n",
      "Class P1: Precision=0.837, Recall=0.704, F1 Score=0.765\n",
      "Class P2: Precision=0.796, Recall=0.928, F1 Score=0.857\n",
      "Class P3: Precision=0.442, Recall=0.211, F1 Score=0.286\n",
      "Class P4: Precision=0.718, Recall=0.727, F1 Score=0.722\n"
     ]
    }
   ],
   "source": [
    "# 1. Random Forest\n",
    "\n",
    "rf_classifier = RandomForestClassifier(n_estimators = 200, random_state=42)\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(y_test, y_pred)\n",
    "\n",
    "print(\"=== RandomForest ===\")\n",
    "print(f\"Accuracy: {acc:.3f}\")\n",
    "for i, cls in enumerate(le.classes_):\n",
    "    print(f\"Class {cls}: Precision={precision[i]:.3f}, Recall={recall[i]:.3f}, F1 Score={f1[i]:.3f}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3ed47001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== XGBoost ===\n",
      "Accuracy: 0.778\n",
      "Class P1: Precision=0.824, Recall=0.761, F1 Score=0.791\n",
      "Class P2: Precision=0.826, Recall=0.914, F1 Score=0.867\n",
      "Class P3: Precision=0.476, Recall=0.309, F1 Score=0.375\n",
      "Class P4: Precision=0.734, Recall=0.736, F1 Score=0.735\n"
     ]
    }
   ],
   "source": [
    "# 2. xgboost\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "xgb_classifier = xgb.XGBClassifier(objective='multi:softmax',  num_class=4)\n",
    "\n",
    "xgb_classifier.fit(X_train, y_train)\n",
    "y_pred = xgb_classifier.predict(X_test)\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(y_test, y_pred)\n",
    "\n",
    "print(\"=== XGBoost ===\")\n",
    "print(f\"Accuracy: {acc:.3f}\")\n",
    "for i, cls in enumerate(le.classes_):\n",
    "    print(f\"Class {cls}: Precision={precision[i]:.3f}, Recall={recall[i]:.3f}, F1 Score={f1[i]:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "70de3417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Decision Tree ===\n",
      "Accuracy: 0.712\n",
      "Class P1: Precision=0.722, Recall=0.724, F1 Score=0.723\n",
      "Class P2: Precision=0.810, Recall=0.826, F1 Score=0.818\n",
      "Class P3: Precision=0.349, Recall=0.331, F1 Score=0.340\n",
      "Class P4: Precision=0.649, Recall=0.626, F1 Score=0.637\n"
     ]
    }
   ],
   "source": [
    "# 3. Decision Tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt_model = DecisionTreeClassifier(max_depth=20, min_samples_split=10)\n",
    "dt_model.fit(X_train, y_train)\n",
    "y_pred = dt_model.predict(X_test)\n",
    "\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(y_test, y_pred)\n",
    "\n",
    "print(\"=== Decision Tree ===\")\n",
    "print(f\"Accuracy: {acc:.3f}\")\n",
    "for i, cls in enumerate(le.classes_):\n",
    "    print(f\"Class {cls}: Precision={precision[i]:.3f}, Recall={recall[i]:.3f}, F1 Score={f1[i]:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "954c2099",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013004 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3157\n",
      "[LightGBM] [Info] Number of data points in the train set: 33651, number of used features: 54\n",
      "[LightGBM] [Info] Start training from score -2.156606\n",
      "[LightGBM] [Info] Start training from score -0.500165\n",
      "[LightGBM] [Info] Start training from score -1.883865\n",
      "[LightGBM] [Info] Start training from score -2.072659\n",
      "=== LightGBM Classifier ===\n",
      "Accuracy: 0.779\n",
      "Class P1: Precision=0.829, Recall=0.772, F1 Score=0.799\n",
      "Class P2: Precision=0.822, Recall=0.917, F1 Score=0.867\n",
      "Class P3: Precision=0.469, Recall=0.289, F1 Score=0.358\n",
      "Class P4: Precision=0.741, Recall=0.739, F1 Score=0.740\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Github\\Credit Risk Prediction\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  message = \"The feature names should match those that were passed during fit.\\n\"\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "\n",
    "# 5. Create a pipeline with StandardScaler and LGBMClassifier\n",
    "lgb_pipeline = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    LGBMClassifier(objective='multiclass', num_class=4, random_state=42)\n",
    ")\n",
    "\n",
    "# 6. Train the model\n",
    "lgb_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# 7. Predict and evaluate\n",
    "y_pred = lgb_pipeline.predict(X_test)\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(y_test, y_pred)\n",
    "\n",
    "print(\"=== LightGBM Classifier ===\")\n",
    "print(f\"Accuracy: {acc:.3f}\")\n",
    "for i, cls in enumerate(le.classes_):\n",
    "    print(f\"Class {cls}: Precision={precision[i]:.3f}, Recall={recall[i]:.3f}, F1 Score={f1[i]:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "050ccd92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Not P3       0.93      0.62      0.74      7088\n",
      "          P3       0.27      0.74      0.39      1325\n",
      "\n",
      "    accuracy                           0.64      8413\n",
      "   macro avg       0.60      0.68      0.57      8413\n",
      "weighted avg       0.82      0.64      0.69      8413\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Binary labels: 1 if class == P3, else 0\n",
    "y_train_p3 = (y_train == 2).astype(int)  # P3 is class index 2\n",
    "y_test_p3 = (y_test == 2).astype(int)\n",
    "\n",
    "clf_p3 = make_pipeline(StandardScaler(), LogisticRegression(class_weight='balanced'))\n",
    "clf_p3.fit(X_train, y_train_p3)\n",
    "p3_preds = clf_p3.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test_p3, p3_preds, target_names=[\"Not P3\", \"P3\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a12ea3dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Github\\Credit Risk Prediction\\.venv\\Lib\\site-packages\\sklearn\\base.py:440: InconsistentVersionWarning: Trying to unpickle estimator StandardScaler from version 1.6.1 when using version 1.7.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  )\n",
      "c:\\Github\\Credit Risk Prediction\\.venv\\Lib\\site-packages\\sklearn\\base.py:440: InconsistentVersionWarning: Trying to unpickle estimator DecisionTreeClassifier from version 1.6.1 when using version 1.7.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  )\n",
      "c:\\Github\\Credit Risk Prediction\\.venv\\Lib\\site-packages\\sklearn\\base.py:440: InconsistentVersionWarning: Trying to unpickle estimator Pipeline from version 1.6.1 when using version 1.7.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  )\n",
      "c:\\Github\\Credit Risk Prediction\\.venv\\Lib\\site-packages\\sklearn\\base.py:440: InconsistentVersionWarning: Trying to unpickle estimator RandomForestClassifier from version 1.6.1 when using version 1.7.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  )\n",
      "c:\\Github\\Credit Risk Prediction\\.venv\\Lib\\site-packages\\sklearn\\base.py:440: InconsistentVersionWarning: Trying to unpickle estimator SVC from version 1.6.1 when using version 1.7.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  )\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Stacking + P3 Override ===\n",
      "Accuracy: 0.776\n",
      "Class P1: Precision=0.837, Recall=0.761, F1 Score=0.798\n",
      "Class P2: Precision=0.825, Recall=0.914, F1 Score=0.867\n",
      "Class P3: Precision=0.444, Recall=0.293, F1 Score=0.353\n",
      "Class P4: Precision=0.735, Recall=0.737, F1 Score=0.736\n"
     ]
    }
   ],
   "source": [
    "# 2. Define base models with scaling\n",
    "rf_model = make_pipeline(StandardScaler(), RandomForestClassifier(random_state=42))\n",
    "xgb_model = make_pipeline(StandardScaler(), xgb.XGBClassifier(objective='multi:softmax', num_class=4))\n",
    "svm_model = make_pipeline(StandardScaler(), SVC(probability=True))\n",
    "dt_model = make_pipeline(StandardScaler(), DecisionTreeClassifier())\n",
    "\n",
    "# 3. Train stacking classifier\n",
    "estimators = [\n",
    "    ('rf', rf_model),\n",
    "    ('xgb', xgb_model),\n",
    "    ('svm', svm_model),\n",
    "    ('dt', dt_model),\n",
    "]\n",
    "\n",
    "stacked_model = StackingClassifier(\n",
    "    estimators=estimators,\n",
    "    final_estimator=LogisticRegression(max_iter=1000),\n",
    "    cv=3,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "stacked_model.fit(X_train, y_train)\n",
    "\n",
    "# 4. Train P3-specialist binary classifier (P3 vs. Not P3)\n",
    "y_train_p3 = (y_train == 2).astype(int)\n",
    "y_test_p3 = (y_test == 2).astype(int)\n",
    "\n",
    "p3_clf = make_pipeline(StandardScaler(), LogisticRegression(class_weight='balanced', max_iter=1000))\n",
    "p3_clf.fit(X_train, y_train_p3)\n",
    "\n",
    "# 5. Predict stacking and P3 probabilities\n",
    "stacked_preds = stacked_model.predict(X_test)\n",
    "p3_probs = p3_clf.predict_proba(X_test)[:, 1]  # P3 confidence\n",
    "\n",
    "# 6. Override logic: change to P3 if probability > threshold\n",
    "threshold = 0.85\n",
    "override_mask = (p3_probs > threshold)\n",
    "stacked_preds[override_mask] = 2  # Class index 2 is P3\n",
    "\n",
    "# 7. Final evaluation\n",
    "acc = accuracy_score(y_test, stacked_preds)\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(y_test, stacked_preds)\n",
    "\n",
    "print(\"=== Stacking + P3 Override ===\")\n",
    "print(f\"Accuracy: {acc:.3f}\")\n",
    "for i, cls in enumerate(le.classes_):\n",
    "    print(f\"Class {cls}: Precision={precision[i]:.3f}, Recall={recall[i]:.3f}, F1 Score={f1[i]:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82f2b12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
